{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3f8134f",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4ceaf8f4d277cad8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Problem set 1\n",
    "\n",
    "This problem set will combine skills from a couple different course units:\n",
    "\n",
    "- **Object-oriented programming**: building classes in Python.  \n",
    "- **Natural Language Processing**: a simple sentiment analyzer in Python.  \n",
    "- **Working with data**: review of working with `.txt` files in Python.\n",
    "\n",
    "At a high-level, your goal will be to create a `SentimentAnalyzer` class, which can produce a *sentiment score* for a piece of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8af4d351",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-57027c38a12a649b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cae266f",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-22c88a6a4ef167be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q1. Create a `TextProcessor` class\n",
    "\n",
    "Create a class called `TextProcessor`, which has the following `self` attributes:\n",
    "\n",
    "- `chars_to_remove`: a `list` of punctuation and other characters to remove.\n",
    "- `separator`: the character to tokenize/`split` on.  \n",
    "- `lower`: a `bool` representing `True` or `False`.  \n",
    "\n",
    "And the following methods:\n",
    "\n",
    "- `__init__`: constructor for `TextProcessor`.  \n",
    "- `tokenize_text`: an instance method that takes in a `text` and a `separator` as arguments and...\n",
    "   - ...removes all characters from `self.chars_to_remove`...\n",
    "   - ...if `self.lower`, makes characters lowercase...\n",
    "   - ...`split`s on `self.separator` and...\n",
    "   - ... returns a list of tokens from `text`.\n",
    "\n",
    "See the `assert` statements for examples, and also this example here:\n",
    "\n",
    "```python\n",
    ">>> tp = TextProcessor(chars_to_remove = ['.', ',', '?', '!'], separator = \" \", lower = True)\n",
    ">>> tp.tokenize_text(text = \"The sky is blue\")\n",
    "[\"The\", \"sky\", \"is\", \"blue\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1db50225",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8b015251985b0b08",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "class TextProcessor:\n",
    "    def __init__(self, chars_to_remove, separator, lower):\n",
    "        \"\"\"\n",
    "        Constructor for TextProcessor.\n",
    "        :param chars_to_remove: List of characters to remove from the text.\n",
    "        \"\"\"\n",
    "        self.chars_to_remove = chars_to_remove\n",
    "        self.separator = separator\n",
    "        self.lower = lower\n",
    "\n",
    "    def tokenize_text(self, text):\n",
    "        \"\"\"\n",
    "        Tokenizes the input text based on the specified separator and removes specified characters.\n",
    "        :param text: String to tokenize.\n",
    "        :return: List of tokens.\n",
    "        \"\"\"\n",
    "        # Remove specified characters\n",
    "        if self.lower:\n",
    "            text = text.lower()\n",
    "        for char in self.chars_to_remove:\n",
    "            text = text.replace(char, \"\")\n",
    "        # Tokenize the text\n",
    "        tokens = text.split(self.separator)\n",
    "        return tokens\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbb032f7",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-cc1e370af352e86a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Testing constructor\n",
    "tp = TextProcessor(chars_to_remove = ['.', ',', '?', '!'], separator = \" \", lower = True)\n",
    "assert tp.chars_to_remove == ['.', ',', '?', '!']\n",
    "assert tp.separator == \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3621275f",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-4dadb47d387af64a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## This cell contains at least one hidden test\n",
    "### Testing tokenizer\n",
    "s1 = \"The quick brown fox jumped over the lazy dog\"\n",
    "assert tp.tokenize_text(s1) == ['the', 'quick', 'brown', 'fox', 'jumped', 'over', 'the', 'lazy', 'dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "801f96e0",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-1fd06de21af7cd60",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "s2 = \"This example has punctuation. Hopefully the tokenizer removes it!\"\n",
    "assert tp.tokenize_text(s2) == ['this',\n",
    " 'example',\n",
    " 'has',\n",
    " 'punctuation',\n",
    " 'hopefully',\n",
    " 'the',\n",
    " 'tokenizer',\n",
    " 'removes',\n",
    " 'it']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd25e9f1",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-fd07b36be93cce22",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "s3 = \"THIS IS ALL CAPS!\"\n",
    "assert tp.tokenize_text(s3) == ['this', 'is', 'all', 'caps']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50d95fa",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e8523b2a1b5578bf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q2. Create a `SentimentAnalyzer` class\n",
    "\n",
    "Now comes the slightly harder part. Create a class called `SentimentAnalyzer`, which takes in the following attributes:\n",
    "\n",
    "- `pos_words`: a `list` of positive words.  \n",
    "- `neg_words`: a `list` of negative words.  \n",
    "- `processor`: a `TextProcessor` instance.  \n",
    "\n",
    "`SentimentAnalyzer` should also have the following *methods*:\n",
    "\n",
    "- `get_sentimental_words`: takes in a `text` as argument, tokenizes `text` with `processor`, and returns a dictionary containing the number of `pos_words`, `neg_words`, and `total_words` (including neutral words). \n",
    "- `score_sentiment`: returns the weighted average sentiment of the dictionary from `get_sentimental_words`, i.e., `((1 * num_pos_words) + (-1 * num_neg_words)) / num_total_words`.\n",
    "\n",
    "\n",
    "**Note**: I know this question is more complicated——fortunately, I've written the tests to deal with each part one at a time, so you can try to implement it piecemeal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34bc0a4b",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-48730d52b0f0ed0e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "class SentimentAnalyzer:\n",
    "    def __init__(self, pos_words, neg_words, processor):\n",
    "        \"\"\"\n",
    "        Constructor for SentimentAnalyzer.\n",
    "        :param pos_words: List of positive words.\n",
    "        :param neg_words: List of negative words.\n",
    "        :param processor: TextProcessor instance for text tokenization.\n",
    "        \"\"\"\n",
    "        self.pos_words = pos_words\n",
    "        self.neg_words = neg_words\n",
    "        self.processor = processor\n",
    "\n",
    "    def get_sentimental_words(self, text):\n",
    "        \"\"\"\n",
    "        Tokenizes the input text and counts positive, negative, and total words.\n",
    "        :param text: String to analyze.\n",
    "        :return: Dictionary with counts of positive, negative, and total words.\n",
    "        \"\"\"\n",
    "        tokens = self.processor.tokenize_text(text)\n",
    "        pos_count = sum(token in self.pos_words for token in tokens)\n",
    "        neg_count = sum(token in self.neg_words for token in tokens)\n",
    "        total_count = len(tokens)\n",
    "        return {\"pos_words\": pos_count, \"neg_words\": neg_count, \"total_words\": total_count}\n",
    "\n",
    "    def score_sentiment(self, text):\n",
    "        \"\"\"\n",
    "        Calculates the weighted average sentiment of the text.\n",
    "        :param text: String to analyze.\n",
    "        :return: Weighted average sentiment score.\n",
    "        \"\"\"\n",
    "        word_counts = self.get_sentimental_words(text)\n",
    "        # Avoid division by zero\n",
    "        if word_counts[\"total_words\"] == 0:\n",
    "            return 0\n",
    "        score = (word_counts[\"pos_words\"] - word_counts[\"neg_words\"]) / word_counts[\"total_words\"]\n",
    "        return score\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81581fe3",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-37e83777d0f71e8b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## initializing params\n",
    "tp = TextProcessor(chars_to_remove=['.', ',', '!', '?'], separator = \" \", lower = True)\n",
    "pos_words = ['love', 'great', 'best', 'good', 'happy']\n",
    "neg_words = ['hate', 'terrible', 'worst', 'bad', 'sad']\n",
    "\n",
    "sa = SentimentAnalyzer(pos_words = pos_words, \n",
    "                       neg_words = neg_words, \n",
    "                       processor=tp)\n",
    "\n",
    "### Checking that constructor works\n",
    "assert sa.pos_words == pos_words\n",
    "assert sa.neg_words == neg_words\n",
    "assert sa.processor.tokenize_text(\"This is a test\") == [\"this\", \"is\", \"a\", \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4dfd4be",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-1daf8dcb0453f3f7",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Checking that get_sentimental_words works\n",
    "s1 = \"I LOVE that movie, it is great.\"\n",
    "s2 = \"I hate that movie, it is terrible.\"\n",
    "s3 = \"I did not love that movie, it was not good\"\n",
    "\n",
    "assert sa.get_sentimental_words(s1) == {'pos_words': 2, 'neg_words': 0, 'total_words': 7}\n",
    "assert sa.get_sentimental_words(s2) == {'pos_words': 0, 'neg_words': 2, 'total_words': 7}\n",
    "assert sa.get_sentimental_words(s3) == {'pos_words': 2, 'neg_words': 0, 'total_words': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a47975ba",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e241666de36fb0b7",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Checking score_sentiment\n",
    "s1 = \"I LOVE that movie, it is great.\"\n",
    "s2 = \"I hate that movie, it is terrible.\"\n",
    "s3 = \"I did not love that movie, it was not good\"\n",
    "\n",
    "assert sa.score_sentiment(s1) > 0\n",
    "assert sa.score_sentiment(s2) < 0\n",
    "assert sa.score_sentiment(s3) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57149f92",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-29492b42754cb147",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q3. Read in `pos_words.txt` and `neg_words.txt` and create a new `SentimentAnalyzer`\n",
    "\n",
    "Read in the two `.txt` files located in the `data` directory. In each case, `split` the contents of the files on the *newline* character and set the result to a variable called `pos_words` or `neg_words`.\n",
    "\n",
    "Then, now you have a more sophisticated sentiment lexicon, let's create a new `SentimentAnalyzer` object with those lists. Call it `analyzer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88222b9c",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2397d56911bcaa69",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "with open(\"data/pos_words.txt\", \"r\") as f:\n",
    "    pos_words = f.read().split(\"\\n\")\n",
    "    \n",
    "with open(\"data/neg_words.txt\", \"r\") as f:\n",
    "    neg_words = f.read().split(\"\\n\")\n",
    "    \n",
    "analyzer = SentimentAnalyzer(pos_words, neg_words, tp)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7b6ba95",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c296cc4d8401eb8a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(pos_words) == 2006\n",
    "assert len(neg_words) == 4783"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd61639d",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-48230fccb640829b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(analyzer.pos_words) == 2006\n",
    "assert len(analyzer.neg_words) == 4783"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c958a67",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c0ee07bcbc1fb914",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q4. Load `restaurant_reviews.csv`\n",
    "\n",
    "Now, read in `data/restaurant_reviews.csv`, which contains a bunch of reviews for different restaurants. Call the result `df_fcores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7213b19b",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4005b84aa47bdfb0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "df_scores = pd.read_csv(\"data/restaurant_reviews.csv\")\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b82d485c",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-fb24834b61b0a75c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(df_scores) == pd.DataFrame\n",
    "assert len(df_scores) == 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075f2a41",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a6c052a0e18feca0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q5. Apply `score_sentiment` to each review\n",
    "\n",
    "Now, use the `apply` function from `pandas` to apply `score_sentiment` to each review, and set the result to a new column called `sentiment_score`. As a hint, you can use apply in the following way:\n",
    "\n",
    "```python\n",
    "df['new_col_name'] = df['col_to_apply'].apply(lambda x: function_to_apply(x))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78b35433",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2109c4275a354952",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "df_scores['sentiment_score'] = df_scores['Review'].apply(lambda x: analyzer.score_sentiment(x))\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c173b52c",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f8f709b3b3e0c34a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert 'sentiment_score' in df_scores.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b350736",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b24df916c84da626",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert df_scores['sentiment_score'].max() == 1\n",
    "assert df_scores['sentiment_score'].min() == -.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d098ccb6",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dac2be5856732a4f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q6. Calculate the mean sentiment per `Liked`\n",
    "\n",
    "Finally, use `groupby` and `mean` to calculate the mean sentiment across categories of the `Liked` column. Call the result `df_grouped`. \n",
    "\n",
    "Is the scored sentiment higher when `Liked==1`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45b15683",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-231b61343911f470",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "df_grouped = df_scores.groupby(\"Liked\").mean(\"sentiment_score\")\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11ecb88a",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-5594d3d47673ff68",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert df_grouped['sentiment_score'][0] < 0\n",
    "assert df_grouped['sentiment_score'][1] > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32648bf",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-57b25ef313cecfe1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Submit!\n",
    "\n",
    "Congratulations——you've now built an entire *class* that can analyze the sentiment of arbitrary text passages! This is a real achievement, and now you can say you built a `SentimentAnalyzer` in Python."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
